{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InventoryAgent: Prototyping a Article Recommendation System for DigiKey Product Retailers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product retailer success depends on accurately managing inventory. Online articles on sites like [EETimes](https://www.eetimes.com/) and [EDN](https://www.edn.com/), can have an outsized affect on sales. Unfortunately, there are often too many articles for short staffed retailers to sort through. Therefore, an opportunity arises for a tool that can sort through a high volume of articles and identify the ones most relevant to a retailers products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can classify articles into three major types based on their relevance to inventory managment of bike products:\n",
    "* Positive: Articles whos content implies a products sales will increase\n",
    "* Negative: Articles whos content implies a products sales will decrease\n",
    "* Neutral: Articles whos content is not relevant to a product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "This notebook demonstrates how to prototype InventoryAgent, an article recommendation system application using data science tools. We built the recommender to identify [EETimes](https://www.eetimes.com/) and [EDN](https://www.edn.com/) articles most relevant to specific products sold by [DigiKey](https://www.digikey.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Results\n",
    "- **Formulate**: Brainstorm ideas as a team\n",
    "- **Collect**: Collect the initial datasets for the model build\n",
    "- **Clean**: Clean the datasets to have the correct shape and content to fit into a model\n",
    "- **Analyze**: Explore the cleaned datasets and edit content as needed\n",
    "- **Model**: Fit different models to the datasets, recommending articles for products, and evaluate there relevance.\n",
    "- **Present**: Present the model outputs in compelling ways through (Examples: dashabords, visualizations or reports).\n",
    "\n",
    "**Run the following notebooks and explore how we prototyped InventoryAgent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Formulate Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we brainstormed as a team around the problem using the [Question Storming](https://experiencinginformation.com/2011/11/02/questionstorming-framing-the-problem/) technique. This allowed us to narrow in on the few ideas that would make the most compeling prototype.\n",
    "\n",
    "The results of our Question Storm can be found [here](https://ridethenextwave-my.sharepoint.com/:x:/p/nick_capaldini/EWQWeLLgcz9KroLso29B4fABtNmctnTHb2WQNEyxtPARqg?e=AsxVzH)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we collect the necessary product text data from [DigiKey](https://www.digikey.com) website.\n",
    "\n",
    "Run the following notebook to extract the necessary text data from DigiKey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Collect Product\n",
    "Raw product data is collected to prepare for cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[01-01-Collect_Product.ipynb](./01-01-Collect_Product.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scrapes product category data from [DigiKey](https://www.digikey.com/en/products), including:\n",
    "\n",
    "- Product category name and sub-category label\n",
    "\n",
    "- URL to each category page\n",
    "\n",
    "- Total number of products per category\n",
    "\n",
    "- Category classification into higher-level groups (e.g., \"Capacitors\", \"Battery Products\")\n",
    "\n",
    "It performs regex-based parsing of embedded JSON-like data and filters out categories with zero product count.\n",
    "\n",
    "Output is stored in the following: `./intermediate_data/Products_List_Raw.json`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Collect Article Link\n",
    "Collect raw article links for later content extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[01-02-Collect_Article_Links.ipynb](./01-02-Collect_Article_Links.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gathers the latest article metadata (titles, URLs, publish dates) from multiple electronics-focused publishers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output is stored in the following: `./intermediate_data/Scraped_Article_Links.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Collect Article Data\n",
    "Raw article data is collected to prepare for cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[01-03-Collect_Article_Data.ipynb](./01-03-Collect_Article_Data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook fetches full article content (body text) for the URLs obtained above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output is stored in the following: `./intermediate_data/Scraped_Article_Raw_Data.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw article and product text is not filtered and cannot be directly used for machine learning. Here we use various methods to clean the text data and prepare it for machine learning.\n",
    "\n",
    "Run the following notebooks to clean the datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Clean Article Data\n",
    "Raw article data is cleaned to prepare for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[02-01-Clean_Products.ipynb](./02-01-Clean_Products.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook processes and filters product category data from DigiKey.\n",
    "\n",
    "- Reads raw category JSON (`./intermediate_data/Products_List_Raw.json`)\n",
    "\n",
    "- Iterates over each category and scrapes a sample of up to 100 listed products per category\n",
    "\n",
    "- Applies light heuristics to extract product metadata\n",
    "\n",
    "- Retains associated metadata such as category and main category group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output is stored in the following: `./intermediate_data/Products_List_Clean.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Clean Product Data\n",
    "Raw product data is cleaned to prepare for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[02-02-Clean_Article_Data.ipynb](./02-02-Clean_Article_Data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook processes the raw scraped article data into clean, readable text.\n",
    "\n",
    "- Loads full-article records from Scraped_Article_Raw_Data.json\n",
    "\n",
    "- Cleans and normalizes article text\n",
    "\n",
    "- Preserves article metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output is stored in the following: `./intermediate_data/product-data-clean.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been cleaned, we can analyze it. Here we do some quick exploration of the cleaned datasets for any insights, ideas, or edits that can inform our model building.\n",
    "\n",
    "Run the following notebooks to analyze the datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Analyze Article Data\n",
    "Cleaned article data is analyzed in anticipation of modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[03-01-AnalyzeArticles.ipynb](./03-01-AnalyzeArticles.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs token-level analysis on cleaned articles to identify frequent keywords and evaluate content length distribution by following steps:\n",
    "\n",
    "- Load cleaned article data from Cleaned_Article_Data.json\n",
    "\n",
    "- Tokenize text while removing manual stopwords\n",
    "\n",
    "- Skip articles with <50 or >3000 valid tokens (truncated if too long)\n",
    "\n",
    "- Count and visualize top 20 most frequent words (after cleaning)\n",
    "\n",
    "- Plot article token count distribution to detect outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output is showed in the following ways:\n",
    "\n",
    "- Bar plot: Top 20 frequent tokens\n",
    "\n",
    "- Bar plot: Filtered article length distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Analyze Product Data\n",
    "Cleaned product data is analyzed in anticipation of modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[03-02-AnalyzeProducts.ipynb](./03-02-AnalyzeProducts.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyzes the cleaned product category list and computes key statistics for visualization by following steps:\n",
    "\n",
    "- Load Products_List_Clean.json\n",
    "\n",
    "- Extract number of items from category names using regex\n",
    "\n",
    "- Normalize and clean category names for better readability\n",
    "\n",
    "- Filter out categories with 0 items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output is showed in the following ways:\n",
    "\n",
    "- Bar plot: Top 10 product-rich categories\n",
    "\n",
    "- Pie chart: Distribution of all categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build a recommendation model using the cleaned datasets.\n",
    "\n",
    "Run the following notebook to build a recommendation model using the data provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[04-ModelRec.ipynb](./04-ModelRec.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs the following steps:\n",
    "\n",
    "- Loads cleaned article texts and product category data.\n",
    "\n",
    "- Preprocesses texts using tokenization and stopword removal (via `gensim.simple_preprocess`).\n",
    "\n",
    "- Combines all article and product texts to build a shared dictionary and TF-IDF representation.\n",
    "\n",
    "- Uses `SparseMatrixSimilarity` to calculate cosine similarity between product and article vectors.\n",
    "\n",
    "- Implements a function to **recommend top-N similar articles** for each product category based on textual similarity.\n",
    "\n",
    "- Filters results to exclude articles with low relevance scores.\n",
    "\n",
    "- Generates a table matching products with their top article recommendations and saves it as a CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output is stored in the following: `./intermediate_data/Product_Article_Matching.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Present Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we set up the recommendation system so that it can be presented in Mesmorizing, Original, Professional, and Simple way to a non-technical audience.\n",
    "\n",
    "Run the following python file to present the recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Deploy Streamlit Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[05-DigiKey_App.py](./05-DigiKey_App.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Streamlit app provides an interactive interface for end-users to:\n",
    "\n",
    "- Search and select a product category\n",
    "\n",
    "  - View 90-day forecast as a quantile dot plot\n",
    "\n",
    "  - Read AI-generated technical summaries\n",
    "\n",
    "  - Access matched articles with relevance scores and clickable links\n",
    "\n",
    "- Explore a full product-article table with rich HTML formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output is showed in the following Features:\n",
    "\n",
    "- Multi-tab layout (Search view + Table view)\n",
    "\n",
    "- Expandable long descriptions with \"See more\"\n",
    "\n",
    "- Clickable product names and article titles with external links\n",
    "\n",
    "- Forecasts and insights auto-rendered per selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Visualize Forecast with Quantile Dot Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[05-02-QuantileDotPlot.ipynb](./05-02-QuantileDotPlot.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates interpretable dot plots for each product category to visualize forecasted unit sales with following steps:\n",
    "\n",
    "- Loads model predictions and dotplot ratio data (`Dot_Plot_Ratio.json`).\n",
    "\n",
    "- For each product category:\n",
    "  \n",
    "  - Multiplies prediction × product count × dot distribution ratio\n",
    "  \n",
    "  - Plots 90-day sales forecast as a quantile dot plot\n",
    "  \n",
    "  - Saves one image per category to `./figures/`\n",
    "\n",
    "\n",
    "Output is stored in the following: `./figures/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Generate Category Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[05-03-GenerateDescription.ipynb](./05-03-GenerateDescription.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the OpenAI GPT-4 model via LangChain to automatically generate summaries for each product category with follow setps:\n",
    "\n",
    "- Loads unique product category names from the matching CSV.\n",
    "\n",
    "- Sends each category name to an LLM prompt asking for a 2–3 line technical summary.\n",
    "\n",
    "- Saves the output in structured JSON format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output is stored in the following: `./intermediate_data/Product_Description.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version and Hardware Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'watermark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mload_ext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwatermark\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwatermark\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-v -m -p ipywidgets,matplotlib,numpy,streamlit,pandas,sklearn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/recommendation_libraries/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2414\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2412\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2413\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2414\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2417\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/recommendation_libraries/lib/python3.11/site-packages/IPython/core/magics/extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_str:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UsageError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing module name.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malready loaded\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m extension is already loaded. To reload it, use:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m module_str)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/recommendation_libraries/lib/python3.11/site-packages/IPython/core/extensions.py:76\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/recommendation_libraries/lib/python3.11/site-packages/IPython/core/extensions.py:91\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[0;32m---> 91\u001b[0m         mod \u001b[38;5;241m=\u001b[39m \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     mod \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[module_str]\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_load_ipython_extension(mod):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/recommendation_libraries/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'watermark'"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -p ipywidgets,matplotlib,numpy,streamlit,pandas,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Authors:**\n",
    "[Salah Mohamoud](mailto:salah.mohamoud.dev@gmail.com),\n",
    "[Sai Keertana Lakku](mailto:saikeertana005@gmail.com),\n",
    "[Zhen Zhuang](mailto:zhuangzhen17cs@gmail.com),\n",
    "[Nick Capaldini](mailto:nick.capaldini@ridethenextwave.com), Ride The Next Wave, May 19, 2025\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
